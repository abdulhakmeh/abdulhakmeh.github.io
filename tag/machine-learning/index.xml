<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning | Abdul Hakmeh</title>
    <link>https://abdulhakmeh.github.io/tag/machine-learning/</link>
      <atom:link href="https://abdulhakmeh.github.io/tag/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Machine Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 27 Sep 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://abdulhakmeh.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Machine Learning</title>
      <link>https://abdulhakmeh.github.io/tag/machine-learning/</link>
    </image>
    
    <item>
      <title>Anomalies Intervals Detection</title>
      <link>https://abdulhakmeh.github.io/project/outlier_detection/</link>
      <pubDate>Tue, 27 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://abdulhakmeh.github.io/project/outlier_detection/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This work is carried out as a PhD. application assign ment with a duration of 10 days. The task is to identify and sort possible outlier intervals from a multivariate time series weather dataset. We use a K-nearest neighbour based method to search for anomalous data points in the data. We then create intervals between the sampled points using the sliding window technique. An approximation to Kullback-Leibler divergence (KL) is used to quantify the degree of di-vergence between two Gaussian distributions (the generated interval distribution and the distribution of the remaining data). At the end, a list of the top intervals is generated to rank the anomalies based on their scores. The results show that the algorithm is able to detect numerous outlier intervals. However, due to the lack of labeled data, we could not numerically evaluate the performance of the algorithm.&lt;/p&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;To evaluate the methodology, we conduct experiments
with real-world multivariate time series data recorded from
ocean observing buoys provided by the National Data Buoy Center (NDBC). The dataset covers six months of hourly
data, beginning in June 2012 and ending in November of the
same year. This period corresponds to the Atlantic hurricane
season, which was particularly active this year with 19
tropical cyclones. 10 of them became hurricanes (winds
over 64 km/h). This information can help to interpret
and evaluate the results by matching the extracted interval
with the already known time window of hurricanes since
the dataset does not provide ground-truth data. Due to the
limited time, we skip the matching.
The variables provided are measurements of significant
wave height Hs, wind speed W, and sea level pressure P.
The data were collected at a site near the Bahamas in the
Atlantic Ocean 1 (23.866° N, 68.481° W).&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;The above figure illustrates the results of applying the KL al-
gorithm based on generated intervals containing pointwise
outliers. The figure shows three time series curves represent-
ing the features of the data set. The red color highlights the
area where the outlier intervals are detected. The numbers
at the top indicate the order of the intervals based on their
intensity. Number 1 has the highest intensity. The results
show that the algorithm is able to detect numerous outlier
intervals, most of which could be identified by eye. Others,
like interval number 4 are hard to identify directly. However,
we could not confirm the results due to the lack of labeled
data.&lt;/p&gt;
&lt;p&gt;For the detailed information about the utilized methods, please refer to my GitHub repository to view the source code or to the attached report file.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On the Impact of Data Sampling Rates on Event Detection Accuracy in Load Signatures using a Shapelet based Approach</title>
      <link>https://abdulhakmeh.github.io/project/shapelet-based-event-detection/</link>
      <pubDate>Thu, 08 Aug 2019 13:39:15 +0200</pubDate>
      <guid>https://abdulhakmeh.github.io/project/shapelet-based-event-detection/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Non-intrusive load monitoring (NILM) is one of the practical applications of the smart electricity grid. NILM provides a comprehensive road-map to detect and determine operation circumstances of an individual appliance from an aggregate load. It can also provide the energy management system with information about appliance-level power consumption, analytical statistics, and detection of energy-hungry appliances to ensure the efficient use of the resources. The event detection is one of the NILM phases that is responsible for detecting state-changes of the appliances.&lt;/p&gt;
&lt;p&gt;In this project, a study is made to measure the impact of data sampling rate on the detection accuracy obtained through an event detection algorithm. Therefore, a machine learning based shapelet approach for electrical appliance use detection is implemented. The fast shapelet approach detects the occurrence of an event that is caused by switching on/off of an electrical appliance. A general architecture is introduced to evaluate the performance through feeding the algorithm with re-sampled data and comparing the obtained accuracy with the sampling rate. Different metrics are used to ensure a comprehensive evaluation; F1-score, confusion matrix, and classification accuracy.&lt;/p&gt;
&lt;h2 id=&#34;data-set&#34;&gt;Data set&lt;/h2&gt;
&lt;p&gt;To evaluate our algorithm the BLUED dataset is used. The BLUED includes one week of the current and the voltage measurements for a family house in Pennsylvania, Pittsburgh. The data collection were taken in October 2011 from nearly 50 electrical devices in the house. The dataset presents the changes in the operating status of each appliance (turn  on/off). The measurements were taken by using two separate systems; one is at the main distribution panel to capture the current and voltage, and the other system is used to register the time stamps for each event. The reason behind choosing the BLUED is that this dataset in its original form provides raw data of the current and the voltage.&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;The results of the experiment have shown that it is possible to detect appliances events with downsampled data using a shapelet based approach. Furthermore, it would have been as well possible that the downsampling improves the accuracy, but the evaluation of the event detection on noisy downsampled data have statistically verified that the lowering of the sampling rate is directly proportional to the accuracy of the detection in a linear form.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
